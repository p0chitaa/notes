{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a99ce77",
   "metadata": {},
   "source": [
    "***EXAM 1 STUFF***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7237f10e",
   "metadata": {},
   "source": [
    "What is runtime complexity of fun()\n",
    "def fun(n): \n",
    "    i,count=n,0 while i>0:\n",
    "    for j in range(i): \n",
    "        count = count+1\n",
    "    i = i//2 \n",
    "    return count\n",
    "    \n",
    "    O(n)\n",
    "\n",
    "What is the time complexity of fun()?\n",
    "def fun(n): \n",
    "    count=0\n",
    "    for i in range(n):\n",
    "        for j in range(i,0,-1):\n",
    "            count = count+1 \n",
    "    return count\n",
    "    \n",
    "    O(n^2)\n",
    "    \n",
    "The time complexity of the following function is (assume n > 0).\n",
    "def rec(n): \n",
    "    if n <= 1:\n",
    "        return 1 \n",
    "    else:\n",
    "        return rec(n-1)+rec(n-2)\n",
    "        \n",
    "    O(2^n)\n",
    "    \n",
    "To determine the efficiency of an algorithm the time factor is measured by:\n",
    "\n",
    "    Key operations?\n",
    "    \n",
    "Consider the following statement: \"If the outer loop enters with the index having value k, the first k positions of the array contain the smallest k elements of the original array, in increasing order.\"\n",
    "The statement is a valid loop invariant for which of the following algorithms, if any?\n",
    "\n",
    "    Bubble Sort\n",
    "    \n",
    "    \n",
    "$n^2 \\in O(n^3)$\n",
    "    TRUE\n",
    "\n",
    "\n",
    "$n^3 \\in O(n^2)$\n",
    "    FALSE\n",
    "\n",
    "\n",
    "$n^3 \\in \\Omega(n^2)$\n",
    "    TRUE\n",
    "    \n",
    "$5^(n+1) \\in \\Theta(5^n)$\n",
    "    TRUE\n",
    "    \n",
    "    \n",
    "An algorithm with asymptotic runtime of $\\Theta(n^2)$ will be slower, on all instances, than an algorithm with time $\\Theta(n log n)$ returning the same result.\n",
    "\n",
    "    FALSE\n",
    "\n",
    "\n",
    "--------\n",
    "\n",
    "Evaluate the following:\n",
    "\n",
    "$T(n) = \\sum_{i=0}^{n} $ $(2+\\sum_{j=i}^{n-1} 3)$\n",
    "\n",
    "**working answer**\n",
    "\n",
    "$ = \\sum_{i=0}^{n}$ $(2+((n-1)-1+1)*3) $\n",
    "\n",
    "$ = \\sum_{i=0}^{n}$ $ 2+(3n-3)$\n",
    "\n",
    "$ = \\sum_{i=0}^{n}$ $ (3n-1) $\n",
    "\n",
    "$ = (n+1)(3n-1)$ -> $3n^2+2n-1$\n",
    "\n",
    "$ => O(n^2) $\n",
    "\n",
    "------\n",
    "\n",
    "\n",
    "True or False 2n3 − n ∈ O(n3).     -> True, $n^3$ $\\in$ $n^3$\n",
    "\n",
    "True or False $2^(n−1)$ ∈ Ω($2^n$).       -> False, One outside bounds, if was 2^n+1 it would be element\n",
    "\n",
    "True or False O(n log n) ⊆ O(log n).    -> True, n=1 both nlogn and log n share element in array\n",
    "\n",
    "True or False O(log n) ⊆ O($2^n$).    -> False, divergent graphs, no overlap or intercepts\n",
    "\n",
    "True or False O(n3.1) ⊆ O(n3).       -> True\n",
    "\n",
    "True or False Bubble sort and Insertion sort have the same worst-case asymptotic runtime. -> True, both $O(n^2)$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Modify binary search to return the index of the first instance of the element.\n",
    "\n",
    "    Yes?\n",
    "\n",
    "Modify binary search to return the indices of the first and last instance of the element.\n",
    "\n",
    "    Yes, can even do it with linear/in place?\n",
    "\n",
    "Given an unsorted array of numbers, return the k largest numbers. At what point does it get more efficient to sort the array?\n",
    "\n",
    "    Linear scan, return largest thing. At best both are linear, average sorting first would be worse\n",
    "\n",
    "\n",
    "Can you extend the binary search of an vector to the search of a 2-d array?\n",
    "\n",
    "    NOOO\n",
    "\n",
    "\n",
    "\n",
    "Why does Quicksort switch to insertion sort?\n",
    "\n",
    "    To make quicksort into a stable sort, quicksort normal wouldnt know what order numbers appeared in, insertion does\n",
    "    \n",
    "    o Quick sort is efficient with very large input\n",
    "     So when quicksort breaks the list down to smaller and smaller lists, insertion sort becomes more efficient.\n",
    "\n",
    "What happens if the partition is 90 - 10?\n",
    "\n",
    "    the complexity stays at nlogn\n",
    "     Update, I believe this changes it to O(nlogn).\n",
    "     nlogn is the average time of quicksort normally\n",
    "    so this is an improvement?\n",
    "\n",
    "Which pivot choice is used by Bentley and McIIlroy?\n",
    "\n",
    "    The left-mostvalue\n",
    "\n",
    "Why would you not used a random pivot?\n",
    "\n",
    "    Seems like randomizing the pivot reduces the chance\n",
    "    of hitting worst case, maybe if we already know some of array is sorted, put pivot after sorted start?\n",
    "\n",
    "What if there are multiple repeated elements? (Better partition?) Heapsort and Quicksort are both n log n. Tradeo􏰂s?\n",
    "\n",
    "     Yep, three way partition\n",
    "\n",
    "     Left, mid, right\n",
    "     0 to left, left to mid, mid to right, right to len(n)\n",
    "    \n",
    "    DUTCH FLAG PROBLEM\n",
    "    \n",
    "\n",
    "Why would one try an iterative implementation of either?\n",
    "\n",
    "    Probably not quicksort since it uses insertion, but maybe mergesort could sometimes run better if incrementing?\n",
    "\n",
    "Which sort would be easier to implement in parallel?\n",
    "\n",
    "    Quicksort\n",
    "\n",
    "\n",
    "-------\n",
    "\n",
    "**GOOD TO KNOW FOR REFERENCE**\n",
    "\n",
    "big omega (lower bound) (best case)\n",
    "big Oh (upper bound) (worst case)\n",
    "big theta (lower and upper bound) (average)\n",
    "\n",
    "\n",
    "Examples of runtime calcs simplified:\n",
    "\n",
    "For loop -> use summation notation like usual\n",
    "\n",
    "While loop -> harder to know for certain, depends on each case:\n",
    "\n",
    "while (i > 0) {\n",
    "    // some computation of cost n\n",
    "    i = i / 2\n",
    "}\n",
    "\n",
    "   this example has a runtime of $\\theta(nlog_2 i)$ since we divide i by 2 each time...\n",
    "   \n",
    "Recursive calls: Remember piecewise functions, base cases { and otherwise, then calculate until find pattern, replace with k then solve...\n",
    "\n",
    "\n",
    "\n",
    " Problem ***COFFEE CAN PROBLEM***\n",
    " \n",
    "You are given a can of coffee beans. Some are white, others black. At each step, take two random beans out. If they are the same colour, throw them out and add a black bean to the can. Otherwise, return the white to the can and discard the black.\n",
    "Questions\n",
    "Does the process terminate?\n",
    "If so, what is the colour of the last bean?\n",
    "\n",
    "\n",
    "Yes, after each step the number of beans in the can by exactly 1, either toss 2 and put new black in OR toss 1 keep other.\n",
    "\n",
    "Color:\n",
    "both black: black -1, white 0\n",
    "one white one black: black -1, white 0\n",
    "both white: black 0, white -2 \n",
    "So white is either same or decreased by two which means\n",
    "\n",
    "if the number of white beans is initially even then the last bean in the jar will be black, and if the number of white beans is initially odd then the last bean in the jar will be white\n",
    "\n",
    "Parity of white is always even, either 0 or even...\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcb47ea",
   "metadata": {},
   "source": [
    "***EXAM 2 STUFF***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8da3f87",
   "metadata": {},
   "source": [
    "Exam 2 Material\n",
    "\n",
    "Quick&Heap Sort Stuff)\n",
    "\n",
    "Why does Quicksort switch to insertion sort?\n",
    "\n",
    "    o Quick sort is efficient with very large input\n",
    "     So when quicksort breaks the list down to smaller and smaller lists, insertion sort becomes more efficient.\n",
    "\n",
    "\n",
    "What happens if the partition is 90 - 10?\n",
    "\n",
    "    the complexity stays at nlogn\n",
    "     Update, I believe this changes it to O(nlogn).\n",
    "     nlogn is the average time of quicksort normally\n",
    "    so this is an improvement?\n",
    "\n",
    "\n",
    "\n",
    "Which pivot choice is used by Bentley and McIIlroy?\n",
    "\n",
    "    The left-mostvalue\n",
    "\n",
    "\n",
    "Why would you not used a random pivot?\n",
    "\n",
    "    Seems like randomizing the pivot reduces the chance\n",
    "    of hitting worst case, maybe if we already know some of array is sorted, put pivot after sorted start?\n",
    "\n",
    "\n",
    "What if there are multiple repeated elements? (Better partition?) Heapsort and Quicksort are both n log n. \n",
    "Tradeoes?\n",
    "\n",
    "    Yep, three way partition\n",
    "\n",
    "     Left, mid, right\n",
    "     0 to left, left to mid, mid to right, right to len(n)\n",
    "\n",
    "o While a well implemented quicksort is usually quicker than\n",
    "heapsort, quicksort can take up to O(n) auxiliary space, where heapsort uses only O(1).\n",
    "\n",
    "     Anything else?\n",
    "\n",
    "\n",
    "Why would one try an iterative implementation of either?\n",
    "\n",
    "    Probably not quicksort since it uses insertion, but maybe mergesort could sometimes run better if incrementing?\n",
    "\n",
    "Which sort would be easier to implement in parallel?\n",
    "\n",
    "    QUICKSORT\n",
    "\n",
    "\n",
    "Sorting Theory & Broken Limits)\n",
    "\n",
    "What does it mean for a sort to be stable?\n",
    "\n",
    "    Stable sorting maintains the order of the two equal balls numbered 8, whereas unstable sorting may invert the relative order of the two 8s.\n",
    "\n",
    "    In simplier terms, if there is an array that has multiple 8s, a stable sort would maintain that the 1st \"8\" always remains before the 2nd \"8\", the 2nd \"8\" after the 1st and before the 3rd, etc.\n",
    "\n",
    "\n",
    "If we could find the median of an array in O(n), could we improve quicksort runtime?\n",
    "\n",
    "    Yes! We could make it to be O(nlogn),as opposed to O(n^2) and $\\Theta (nlog(n))$\n",
    "\n",
    "\n",
    "Can we make all sorting algorithms seen previously stable?\n",
    "\n",
    "    Yes? Quicksort could be modified but maybe slower? Others should be good and/or are already\n",
    "\n",
    "\n",
    "Unweighted Graph Stuff)\n",
    "\n",
    "State an efficient algorithm to find the diameter of a graph, the length of the largest shortest path in the graph. (No coding required; bird-s eye view sufficient.)\n",
    "\n",
    "    Several options, if unweighted, taking last of breath first search could work,\n",
    "    If weighted, Dijkstra/Bell-Ford + some sort of heap / other data structure (linked list, etc) will work too\n",
    "\n",
    "\n",
    "Trace the Topsort algorithm by displaying the successive changes to the stack variable as it executes the call on Slide 45.\n",
    "\n",
    "    ?\n",
    "\n",
    "\n",
    "Is the DFS of a graph unique if you fix the root? Is the BFS of a graph unique if you fix the root? Is the number of edges in a DFS fixed?\n",
    "\n",
    "    DFS if fixed graph and fixed root is not unique, False\n",
    "    \n",
    "    BFS if fixed graph and fixed root is not unique, False\n",
    "    \n",
    "    **BECAUSE USING BFS OR DFS, GIVEN MOST GRAPHS, YOU CAN FIND THE ANSWER MORE THAN ONE WAY\n",
    "\n",
    "    Given a fixed graph, the number of edges in a Depth First Search tree is unique: TRUE\n",
    "\n",
    "\n",
    "Weighted Graph Stuff)\n",
    "\n",
    "    can you stop early?\n",
    "    \"you do the outer loop of bellman-ford and nothing changes, there's no point in doing it again. It's not going to change. Because everything is based on the distance vector. So if nothing has changed in one iteration, you just get out.\"\n",
    "\n",
    "\n",
    "Can you name (describe) an algorithm illustrating each of the above techniques?\n",
    "\n",
    "    (Different for each case, brute force can be as simple as for loops, quicksort, etc\n",
    "    Recursion algorithms allow simplification for later\n",
    "    many other techniques, see algorithms listed below.\n",
    "\n",
    "\n",
    "Can we find the maximum weight spanning tree by reversing the weights and running Kruskal?\n",
    "\n",
    "    False? Also Kruskal would fail with negative weights\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "Can we find the tree of longuest paths by reversing the weights and running Bellman-Ford?\n",
    "AKA We can find the tree of longest paths in a graph by reversing the cost on the edges and running Bellman-Ford: \n",
    "    \n",
    "    FALSE\n",
    "    \n",
    "    \n",
    "On an undirected weighted graph with positive\n",
    "weights, negating the weights, then finding the shortest paths by Bellman-Ford, will always yield the longest paths?\n",
    "\n",
    "    False\n",
    "\n",
    "Is the minimum spanning tree unique if the edge weights are distinct?\n",
    "aka Every weighted undirected graph has a unique minimum spanning tree?\n",
    "\n",
    "    False\n",
    "\n",
    "If you multiply all edge weights by some factor, is the tree of shortest path the same?\n",
    "    \n",
    "    True\n",
    "\n",
    "If a graph has negative cycles, does it imply that no pair of nodes have a finite cost shortest path?\n",
    "\n",
    "    Maybe not...??\n",
    "    Yes, there would be no pair of nodes with a finite cost as we would be in a loop/stuck choosing more and more negative values (think about driving downhill forever since that would be most effective /greedy)\n",
    "\n",
    "\n",
    "If a graph has negative cycles, no pair of nodes has a finite minimum length path between them.\n",
    "\n",
    "    FALSE\n",
    "    \n",
    "On a fixed graph, Prim and Kruskal always produce the same tree, though from very different techniques.\n",
    "\n",
    "    DO PRIM A KRUSKAL MAKE SAME TREE?\n",
    "\n",
    "    FALSE,\n",
    "    \n",
    "    Prim's algorithm works on undirected graphs only, since the concept of an MST assumes that graphs are inherently undirected. \n",
    "    \n",
    "    Also, Dijkstra may NOT be valid for negative weighted graphs\n",
    "\n",
    "\n",
    "\n",
    "Animal Zoo Complexity P NP Stuff)\n",
    "\n",
    "What would you conclude if I proved that TSP is in P?\n",
    "    \n",
    "    P = NP = NPC\n",
    "    \n",
    "    If TSP (Travel Salesman Problem) is P then crypto and lots of stuff are broken (hard is easy)\n",
    "\n",
    "What would you conclude if I proved that TSP is not in P?\n",
    "\n",
    "    IF TSP is Not in P, then Hard things are hard and may not all be solvable...?\n",
    "\n",
    "    HARD STUFF WOULD NOT BE IN POLYTIME\n",
    "\n",
    "\n",
    "\n",
    "Other Exam 2 Material:\n",
    "\n",
    "If you insert the following array, [18,5,7,10,3,6] in the order given, into a min-heap, which of the following is the resulting heap when finished?\n",
    "\n",
    "    The correct answer is: [6, 3, 5, 6, 18, 10, 7]\n",
    "    \n",
    "    heap counts how many numbers there are, we use min-heap so it takes smallest put it at front, then ??\n",
    "\n",
    "John claims he can replace the library general-purpose qsort with an algorithm with a runtime of\n",
    "\"O(n log(log n)) on an array of n elements. There is not enough information to know whether John's algorithm is correct.\n",
    "\n",
    "    FALSE\n",
    "\n",
    "\n",
    "What is not true about sorting algorithms -> list of 4\n",
    "\n",
    "\n",
    "    a. Any comparison based sorting algorithm can be made stable by using position as a criteria when two elements are compared.\n",
    "    b. Heap Sort is NOT a comparison based sorting algorithm.\n",
    "    c. Counting Sort is not a comparison based sorting algortihm.\n",
    "    d. The minimum possible time complexity of a comparison based \" sorting algorithm is \u001d",
    "(\u001d",
    " log \u001d",
    ") for a random input array.\n",
    "\n",
    "    The correct answer is: Heap Sort is not a comparison based sorting algorithm.\n",
    "    \n",
    "    Heap sort IS a comparison based algo!\n",
    "    \n",
    "    \n",
    "Suppose we have a O(n) time algorithm that finds median\n",
    "of an unsorted array. Now consider a QuickSort implementation where we first find a median using the above algorithm, then use this median as pivot. What will be the worst case time complexity of this modified QuickSort.\n",
    "\n",
    "    O(n log n),\n",
    "    \n",
    "    Recall what we discussed earlier, if we know the median, our worst case goes from O(n^2) -> O(nlogn)\n",
    "    \n",
    "    \n",
    "A sorting technique is called stable if:\n",
    "\n",
    "    It maintains the relative order of occurrence of non-distinct elements!\n",
    "\n",
    "Consider the Quicksort algorithm. Suppose there is a\n",
    "procedure for finding a pivot element which splits the list into two sub-lists each of which contains at least one-fifth of the\n",
    "elements. Let T(n) be the number of comparisons required to sort n elements. Then T(n) is\n",
    "\n",
    "    T(n/5) + T(4n/5) + n\n",
    "    \n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882f0e93",
   "metadata": {},
   "source": [
    "***COVERED AFTER EXAM 2***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bbd682",
   "metadata": {},
   "source": [
    "Dynamic Programing (DP):\n",
    "\n",
    "Can you write the recursive algos iteratively? \n",
    "\n",
    "    Yes, every time we do homework that we want to do recursion but end up doing it iterately, for loop, etc\n",
    "\n",
    "Can you write the iterative algos recursively? \n",
    "\n",
    "    We are afraid, but it is possible\n",
    "\n",
    "Can you precisely prove every runtime claim?\n",
    "\n",
    "    Once we are grad students we can easier, but in theory yes\n",
    "\n",
    "The python implementation of dictionary:\n",
    "How is space allocated?\n",
    "\n",
    "    This sums up to at least 12 bytes on a 32bit machine and 24 bytes on a 64bit machine. The dictionary starts with 8 empty buckets. This is then resized by doubling the number of entries whenever its capacity is reached.\n",
    "\n",
    "\n",
    "Is the hash function the same for all data types? Are they using open addressing or chaining?\n",
    "\n",
    "    In python it is chanining? \n",
    "\n",
    "\n",
    "Really Hard Problems:\n",
    "\n",
    "    Maybe how to prune / pruning trees?\n",
    "    \n",
    "Given a network of n nodes, how many possible tours are there?\n",
    "\n",
    "    ?\n",
    "\n",
    "\n",
    "Network Flow:\n",
    "\n",
    "    ?\n",
    "    \n",
    "    \n",
    "Linear Programming:\n",
    "\n",
    "    ?\n",
    "    \n",
    "    \n",
    "Crypto:\n",
    "\n",
    "    CRYPTO IS NOT ON FINAL\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
